{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a231f9",
   "metadata": {},
   "source": [
    "### Continual learning and generative replay\n",
    "\n",
    "#### Installation:\n",
    "\n",
    "Local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip tensorflow-macos==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f726ba-f622-4c8b-b0af-9330f10a4277",
   "metadata": {},
   "source": [
    "Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba8f20-ee5d-44c4-8d59-358fb79192c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wonderwords evaluate datasets accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12409883",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from continual_learning_utils import *\n",
    "from grid_environment_utils import * \n",
    "from testing_utils import * \n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b275136-35f1-4b43-9070-3eb14e27164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_script(name_or_path='spatial_model', \n",
    "                       num_epochs=3,\n",
    "                       output_dir='./clm_script',\n",
    "                       save_steps=100,\n",
    "                       lr=5e-05):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    ! python ./run_clm.py \\\n",
    "        --model_name_or_path {name_or_path} \\\n",
    "        --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --validation_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'steps' \\\n",
    "        --save_steps {save_steps} \\\n",
    "        --learning_rate {lr} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ed38f-d6b0-443b-ab78-e94cbd3e07e5",
   "metadata": {},
   "source": [
    "#### Train base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516da01f-90f9-4f0e-8cc8-a04198c87d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_strs = []\n",
    "for i in range(3000):\n",
    "    nouns = [r.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\") for _ in range(9)]\n",
    "    grid = create_unique_random_grid(nouns)\n",
    "    training_strs.extend(get_all_paths_for_grid(grid))\n",
    "\n",
    "print(f\"{len(training_strs)} shortest paths on arbitrary grids generated for pre-training.\")\n",
    "\n",
    "!mkdir base_model\n",
    "text_file = open(\"base_model/train.txt\", \"w\")\n",
    "n = text_file.write('\\n'.join(training_strs))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(name_or_path='gpt2', output_dir='base_model', num_epochs=5, save_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8023c6d-8180-48c3-ab08-5f73655c74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r base_model/* base_model_backup/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8424d28",
   "metadata": {},
   "source": [
    "#### Test generative replay\n",
    "\n",
    "Let's first create training data for 5 environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d2d1e-ab29-4f22-935e-fede85bef7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_on_env(training_strs, testing_strs, eps=10, lr=5e-05, num_train=100, env=0, base_model='base_model', generated_strs=None):\n",
    "    !rm -rf spatial_model_{env}\n",
    "    !mkdir spatial_model_{env}\n",
    "    \n",
    "    text_file = open(f\"spatial_model_{env}/train.txt\", \"w\")\n",
    "    \n",
    "    # There are 100 training sequence so by default use them all\n",
    "    list_to_write = training_strs[env][0:num_train]\n",
    "    \n",
    "    if generated_strs is not None:\n",
    "        list_to_write.extend(generated_strs)\n",
    "\n",
    "    # We oversample the list of training sequences by a factor of five (len(list_to_write)*5)\n",
    "    # This avoids overfitting to a particular sequence order\n",
    "    list_to_write = np.random.choice(list_to_write, 1000).tolist()\n",
    "    n = text_file.write('\\n'.join(list_to_write))\n",
    "    text_file.close()\n",
    "\n",
    "    text_file = open(f\"spatial_model_{env}/test.txt\", \"w\")\n",
    "    n = text_file.write('\\n'.join(testing_strs[env]))\n",
    "    text_file.close()\n",
    "    \n",
    "    train_model_script(name_or_path=base_model, \n",
    "                       output_dir=f'spatial_model_{env}', \n",
    "                       num_epochs=eps, \n",
    "                       save_steps=2000,\n",
    "                       lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698e1f8-8c87-4c13-9d74-8d0f869ed4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_replay(model, num=100, temperature=1):\n",
    "    examples = []\n",
    "    while len(examples) < num:\n",
    "        out = model.continue_input(\"FROM:\", \n",
    "                                   do_sample=True,\n",
    "                                   temperature=temperature)\n",
    "        # Leave out the last sequence as it stopped midway through\n",
    "        examples.extend(out.split('\\n')[:-1])\n",
    "    shuffle(examples)\n",
    "    return examples\n",
    "\n",
    "def experience_replay(i, train_size=100, sample_size=10):\n",
    "    # Get sample_size items from the first train_size items of each previous environment\n",
    "    train_list = [training_strs[j][0:train_size] for j in range(0,i)]\n",
    "    # Flatten this list\n",
    "    train_list = [x for xs in train_list for x in xs]\n",
    "    return random.choices(train_list, k=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89307b1-382e-461b-89a9-d634cf2f1e9d",
   "metadata": {},
   "source": [
    "#### Exploring the effect of different amounts of generative replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af57de-3e60-482c-82b2-a8521864946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "word_freq_results = []\n",
    "\n",
    "num_env = 5\n",
    "num_trials = 1\n",
    "\n",
    "params_to_test = [{'sample_size': 0, 'train_size': 100, 'temp': 1.0},\n",
    "                  {'sample_size': 50, 'train_size': 100, 'temp': 1.0},\n",
    "                  {'sample_size': 100, 'train_size': 100, 'temp': 1.0},\n",
    "                  {'sample_size': 500, 'train_size': 100, 'temp': 1.0}]\n",
    "\n",
    "\n",
    "for trial_num in range(num_trials):\n",
    "    \n",
    "    training_strs, testing_strs = prepare_data()\n",
    "\n",
    "    for params in params_to_test:\n",
    "        train_size = params['train_size']\n",
    "        sample_size = params['sample_size']\n",
    "        temp = params['temp']\n",
    "                \n",
    "        for i in range(num_env):\n",
    "            if temp == -1:\n",
    "                generated_strs = experience_replay(i, train_size=train_size, sample_size=sample_size) if i > 0 else []\n",
    "            else:\n",
    "                generated_strs = generative_replay(GPT(base_model=f'spatial_model_{i-1}'), num=sample_size, temperature=temp) if i > 0 else []\n",
    "                \n",
    "            print(generated_strs)\n",
    "            train_on_env(training_strs, testing_strs, num_train=train_size, env=i, base_model='base_model' if i == 0 else f'spatial_model_{i-1}', generated_strs=generated_strs)\n",
    "            \n",
    "            # Save the data from generative / experience replay, and unique locations, for analysis\n",
    "            locs = get_unique_locations(generated_strs)\n",
    "            word_freq_results.append({'model': i, \n",
    "                                      'locs': locs, \n",
    "                                      'temp': temp, \n",
    "                                      'train_size': train_size, \n",
    "                                      \"sample_size\": sample_size, \n",
    "                                      \"seqs\": generated_strs, \n",
    "                                      \"training_strs\": training_strs, \n",
    "                                      \"testing_strs\": testing_strs})\n",
    "            with open('word_freq_results_sample.pkl', 'wb') as file:\n",
    "                pickle.dump(word_freq_results, file)\n",
    "            \n",
    "            # Test on all environments\n",
    "            model = GPT(base_model=f'spatial_model_{i}')\n",
    "            for j in range(num_env):\n",
    "                with open(f\"spatial_model_{j}/test.txt\", 'r') as file:\n",
    "                    test_data = [line.strip() for line in file]\n",
    "                accuracy = test_accuracy(model, test_data)\n",
    "                results.append([i, j, accuracy, temp, train_size, sample_size])\n",
    "    \n",
    "            # Save at intervals in case code errors before end\n",
    "            with open('replay_results_sample.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['trained_on', 'tested_on', 'accuracy', 'temp', 'train_size', 'sample_size'])\n",
    "                writer.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1982d-c4bb-4c36-8560-f09d6c0c1686",
   "metadata": {},
   "source": [
    "#### Aggregate across trials and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074c510-8ef6-4b41-a6b1-d8cc168fb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('replay_sample_results.csv')\n",
    "\n",
    "# Group by 'Sample_Size', 'Trained_On', and 'Tested_On', and calculate mean and SEM\n",
    "grouped = df.groupby(['sample_size', 'trained_on', 'tested_on'])\n",
    "mean_df = grouped['accuracy'].mean().reset_index()\n",
    "sem_df = grouped['accuracy'].sem().reset_index()\n",
    "\n",
    "sem_df['accuracy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72353a90-3b98-43c9-8805-6260d793dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique sample sizes and number of environments\n",
    "sample_sizes = mean_df['sample_size'].unique()\n",
    "num_env = df['trained_on'].nunique()\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(len(sample_sizes), 1, figsize=(10, 15), sharex=True)\n",
    "\n",
    "# Iterate over each sample size and create a subplot\n",
    "for i, sample_size in enumerate(sample_sizes):\n",
    "    df_sample_mean = mean_df[mean_df['sample_size'] == sample_size]\n",
    "    df_sample_sem = sem_df[sem_df['sample_size'] == sample_size]\n",
    "\n",
    "    for tested_on in range(num_env):\n",
    "        # Filter the mean and SEM dataframes for the specific 'Tested_On' value\n",
    "        means = df_sample_mean[df_sample_mean['tested_on'] == tested_on]['accuracy']\n",
    "        sems = df_sample_sem[df_sample_sem['tested_on'] == tested_on]['accuracy']\n",
    "        trained_on_values = df_sample_mean[df_sample_mean['tested_on'] == tested_on]['trained_on']\n",
    "        \n",
    "        # Plot error bars\n",
    "        axes[i].errorbar(trained_on_values, means, yerr=sems, label=f'Tested on Env {tested_on}', marker='o')\n",
    "\n",
    "    letter = string.ascii_lowercase[i]\n",
    "    axes[i].set_title(f'{letter}) {sample_size} self-generated samples')\n",
    "    axes[i].set_ylabel('accuracy')\n",
    "    axes[i].legend()\n",
    "\n",
    "# Set common labels and title\n",
    "axes[-1].set_xlabel('Trained On Environment')\n",
    "axes[-1].set_xticks(range(num_env))\n",
    "# plt.suptitle('Mean Model Accuracy Across Trials with SEM')\n",
    "plt.savefig('Number of samples effect three trials.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3401d-b3fe-4930-a79e-9cdce89dedbf",
   "metadata": {},
   "source": [
    "#### Explore the effect of different temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345f91e-a145-48d0-81ca-4a64e9a8d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "word_freq_results = []\n",
    "\n",
    "num_env = 3\n",
    "num_trials = 1\n",
    "\n",
    "params_to_test = [{'sample_size': 100, 'train_size': 100, 'temp': 0.5},\n",
    "                  {'sample_size': 100, 'train_size': 100, 'temp': 1.0},\n",
    "                  {'sample_size': 100, 'train_size': 100, 'temp': 1.5}]\n",
    "\n",
    "for trial_num in range(num_trials):\n",
    "    \n",
    "    training_strs, testing_strs = prepare_data()\n",
    "\n",
    "    for params in params_to_test:\n",
    "        train_size = params['train_size']\n",
    "        sample_size = params['sample_size']\n",
    "        temp = params['temp']\n",
    "                \n",
    "        for i in range(num_env):\n",
    "            if temp == -1:\n",
    "                generated_strs = experience_replay(i, train_size=train_size, sample_size=sample_size) if i > 0 else []\n",
    "            else:\n",
    "                generated_strs = generative_replay(GPT(base_model=f'spatial_model_{i-1}'), num=sample_size, temperature=temp) if i > 0 else []\n",
    "                \n",
    "            print(generated_strs)\n",
    "            train_on_env(training_strs, testing_strs, num_train=train_size, env=i, base_model='base_model' if i == 0 else f'spatial_model_{i-1}', generated_strs=generated_strs)\n",
    "            \n",
    "            # Save the data from generative / experience replay, and unique locations, for analysis\n",
    "            locs = get_unique_locations(generated_strs)\n",
    "            word_freq_results.append({'model': i, \n",
    "                                      'locs': locs, \n",
    "                                      'temp': temp, \n",
    "                                      'train_size': train_size, \n",
    "                                      \"sample_size\": sample_size, \n",
    "                                      \"seqs\": generated_strs, \n",
    "                                      \"training_strs\": training_strs, \n",
    "                                      \"testing_strs\": testing_strs})\n",
    "            with open('word_freq_results_temp.pkl', 'wb') as file:\n",
    "                pickle.dump(word_freq_results, file)\n",
    "            \n",
    "            # Test on all environments\n",
    "            model = GPT(base_model=f'spatial_model_{i}')\n",
    "            for j in range(num_env):\n",
    "                with open(f\"spatial_model_{j}/test.txt\", 'r') as file:\n",
    "                    test_data = [line.strip() for line in file]\n",
    "                accuracy = test_accuracy(model, test_data)\n",
    "                results.append([i, j, accuracy, temp, train_size, sample_size])\n",
    "    \n",
    "            # Save at intervals in case code errors before end\n",
    "            with open('replay_results_temp.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['trained_on', 'tested_on', 'accuracy', 'temp', 'train_size', 'sample_size'])\n",
    "                writer.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09895c27-428a-474b-a228-5bc0627160c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('replay_temp_results.csv')\n",
    "mean_df = df.groupby(['Temperature', 'Trained_On', 'Tested_On'])['Accuracy'].mean().reset_index()\n",
    "sem_df = df.groupby(['Temperature', 'Trained_On', 'Tested_On'])['Accuracy'].sem().reset_index()\n",
    "\n",
    "temperatures = mean_df['Temperature'].unique()\n",
    "num_env = df['Trained_On'].nunique()\n",
    "\n",
    "fig, axes = plt.subplots(len(temperatures), 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "for i, temp in enumerate(temperatures):\n",
    "    df_temp_mean = mean_df[mean_df['Temperature'] == temp]\n",
    "    df_temp_sem = sem_df[sem_df['Temperature'] == temp]\n",
    "\n",
    "    if df_temp_mean.empty or df_temp_sem.empty:\n",
    "        continue\n",
    "\n",
    "    for tested_on in range(num_env):\n",
    "        means = df_temp_mean[df_temp_mean['Tested_On'] == tested_on]['Accuracy']\n",
    "        sems = df_temp_sem[df_temp_sem['Tested_On'] == tested_on]['Accuracy']\n",
    "        trained_on_values = df_temp_mean[df_temp_mean['Tested_On'] == tested_on]['Trained_On']\n",
    "\n",
    "        if means.empty or sems.empty or trained_on_values.empty:\n",
    "            continue\n",
    "\n",
    "        axes[i].plot(trained_on_values, means, label=f'Tested on Env {tested_on}', marker='o')\n",
    "\n",
    "    letter = string.ascii_lowercase[i]\n",
    "    axes[i].set_title(f'{letter}) Temperature of {temp}')\n",
    "    axes[i].set_ylabel('Accuracy')\n",
    "    axes[i].legend()\n",
    "\n",
    "axes[-1].set_xticks(range(num_env))\n",
    "axes[-1].set_xlabel('Trained On Environment')\n",
    "plt.savefig('Temperature_effect.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa57fa7-dabf-4983-aa55-96e4a0bd2201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_counts = {(model, temp): {env: 0 for env in range(num_env)} for model in range(5) for temp in temps}\n",
    "\n",
    "for record in word_freq_results:\n",
    "    model, temp, locs = record['model'], record['temp'], record['locs']\n",
    "    for word in locs:\n",
    "        if word in all_env_words:\n",
    "            for env in range(num_env):\n",
    "                if word in get_unique_locations(training_strs[env]):\n",
    "                    word_counts[(model, temp)][env] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97e6c2-3536-4180-86fd-403fc562082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for each temperature\n",
    "fig, axes = plt.subplots(len(temps), 1, figsize=(8, 10))\n",
    "bar_width = 0.2\n",
    "num_groups = 5  # Assuming 5 models\n",
    "group_width = num_env * bar_width\n",
    "\n",
    "# Iterate through each temperature and plot on a separate axis\n",
    "for i, temp in enumerate(temps):\n",
    "    for env in range(num_env):\n",
    "        frequencies = [word_counts[(model, temp)][env] for model in range(num_groups)]\n",
    "        axes[i].bar([x * (group_width + bar_width) + env * bar_width for x in range(num_groups)], frequencies, width=bar_width, label=f'Env {env} locations')\n",
    "    \n",
    "    # Set the title for each subplot\n",
    "    letter = string.ascii_lowercase[i]\n",
    "    axes[i].set_title(f'{letter}) Location Distributions for Temperature {temp}')\n",
    "    axes[i].legend()\n",
    "    axes[i].set_xlabel('Trained On Environment')\n",
    "    axes[i].set_ylabel('Number of Locations')\n",
    "    axes[i].set_xticks([x * (group_width + bar_width) + group_width / 2 for x in range(num_groups)], range(num_groups))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('location_distributions.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c290f6-b60a-4e68-9834-9b395403ea28",
   "metadata": {},
   "source": [
    "#### Generated vs. imagined sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7128f-dd62-49cd-999f-31a18d189472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "word_freq_results = []\n",
    "\n",
    "num_env = 5\n",
    "num_trials = 3\n",
    "\n",
    "params_to_test = [{'sample_size': 50, 'train_size': 20, 'temp': -1},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 0.3},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 0.6},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 0.9},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 1.2},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 1.5},\n",
    "                  # testing effect of sample size\n",
    "                  {'sample_size': 0, 'train_size': 20, 'temp': 1.0},\n",
    "                  {'sample_size': 10, 'train_size': 20, 'temp': 1.0},\n",
    "                  {'sample_size': 50, 'train_size': 20, 'temp': 1.0},\n",
    "                  {'sample_size': 100, 'train_size': 20, 'temp': 1.0},\n",
    "                  {'sample_size': 200, 'train_size': 20, 'temp': 1.0},\n",
    "                  # testing effect of train_size\n",
    "                  {'sample_size': 10, 'train_size': 20, 'temp': -1},\n",
    "                  {'sample_size': 100, 'train_size': 20, 'temp': -1},\n",
    "                  {'sample_size': 200, 'train_size': 20, 'temp': -1},]\n",
    "\n",
    "for trial_num in range(num_trials):\n",
    "    \n",
    "    training_strs, testing_strs = prepare_data(short_paths=True)\n",
    "\n",
    "    for params in params_to_test:\n",
    "        train_size = params['train_size']\n",
    "        sample_size = params['sample_size']\n",
    "        temp = params['temp']\n",
    "                \n",
    "        for i in range(num_env):\n",
    "            if temp == -1:\n",
    "                generated_strs = experience_replay(i, train_size=train_size, sample_size=sample_size) if i > 0 else []\n",
    "            else:\n",
    "                generated_strs = generative_replay(GPT(base_model=f'spatial_model_{i-1}'), num=sample_size, temperature=temp) if i > 0 else []\n",
    "                \n",
    "            print(generated_strs)\n",
    "            train_on_env(training_strs, \n",
    "                         testing_strs, \n",
    "                         eps=20, \n",
    "                         lr=5e-05,\n",
    "                         num_train=train_size, \n",
    "                         env=i, \n",
    "                         base_model='base_model_b8' if i == 0 else f'spatial_model_{i-1}', \n",
    "                         generated_strs=generated_strs)\n",
    "            \n",
    "            # Save the data from generative / experience replay, and unique locations, for analysis\n",
    "            locs = get_unique_locations(generated_strs)\n",
    "            word_freq_results.append({'model': i, \n",
    "                                      'locs': locs, \n",
    "                                      'temp': temp, \n",
    "                                      'train_size': train_size, \n",
    "                                      \"sample_size\": sample_size, \n",
    "                                      \"seqs\": generated_strs, \n",
    "                                      \"training_strs\": training_strs, \n",
    "                                      \"testing_strs\": testing_strs})\n",
    "            with open('word_freq_results_imagined.pkl', 'wb') as file:\n",
    "                pickle.dump(word_freq_results, file)\n",
    "            \n",
    "            # Test on all environments\n",
    "            model = GPT(base_model=f'spatial_model_{i}')\n",
    "            for j in range(num_env):\n",
    "                if j<=i:\n",
    "                    with open(f\"spatial_model_{j}/test.txt\", 'r') as file:\n",
    "                        test_data = [line.strip() for line in file]\n",
    "                        print(test_data)\n",
    "                    accuracy = test_accuracy(model, test_data)\n",
    "                    results.append(['next_node', i, j, accuracy, temp, train_size, sample_size])\n",
    "                    accuracy = shortest_path_accuracy(model, \n",
    "                                                      test_data_subset(test_data, training_strs[j][:train_size]), \n",
    "                                                      training_strs[j] + testing_strs[j])\n",
    "                    results.append(['shortest_path', i, j, accuracy, temp, train_size, sample_size])\n",
    "    \n",
    "            # Save at intervals in case code errors before end\n",
    "            with open('replay_results_imagined.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['test_type', 'trained_on', 'tested_on', 'accuracy', 'temp', 'train_size', 'sample_size'])\n",
    "                writer.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09289ae7-5096-4ddd-9b61-b3a02febca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('replay_results_imagined.csv')\n",
    "df = df[df['test_type'] == 'shortest_path']\n",
    "\n",
    "# Group by 'Sample_Size', 'Trained_On', and 'Tested_On', and calculate mean and SEM\n",
    "grouped = df.groupby(['temp', 'trained_on', 'tested_on'])\n",
    "mean_df = grouped['accuracy'].mean().reset_index()\n",
    "sem_df = grouped['accuracy'].sem().reset_index()\n",
    "\n",
    "sem_df['accuracy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbcb7d-6fce-48d4-90b9-e638df885f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = mean_df['temp'].unique()\n",
    "num_env = df['trained_on'].nunique()\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(len(vals), 1, figsize=(8, 16), sharex=True)\n",
    "\n",
    "# Iterate over each sample size and create a subplot\n",
    "for i, val in enumerate(vals):\n",
    "    df_sample_mean = mean_df[mean_df['temp'] == val]\n",
    "    df_sample_sem = sem_df[sem_df['temp'] == val]\n",
    "\n",
    "    for tested_on in range(num_env):\n",
    "        # Filter the mean and SEM dataframes for the specific 'Tested_On' value\n",
    "        means = df_sample_mean[df_sample_mean['tested_on'] == tested_on]['accuracy']\n",
    "        sems = df_sample_sem[df_sample_sem['tested_on'] == tested_on]['accuracy']\n",
    "        trained_on_values = df_sample_mean[df_sample_mean['tested_on'] == tested_on]['trained_on']\n",
    "        \n",
    "        # Plot error bars\n",
    "        axes[i].errorbar(trained_on_values, means, yerr=sems, label=f'Tested on Env {tested_on}', marker='o')\n",
    "\n",
    "    letter = string.ascii_lowercase[i]\n",
    "    axes[i].set_title(f'{letter}) {val} self-generated samples')\n",
    "    axes[i].set_ylabel('Accuracy')\n",
    "    axes[i].set_ylim((0,1))\n",
    "    axes[i].legend()\n",
    "\n",
    "# Set common labels and title\n",
    "axes[-1].set_xlabel('Trained On Environment')\n",
    "axes[-1].set_xticks(range(num_env))\n",
    "# plt.suptitle('Mean Model Accuracy Across Trials with SEM')\n",
    "plt.savefig('Number of samples effect three trials.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c476-d762-4322-b1fc-0bc02c0fed0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
