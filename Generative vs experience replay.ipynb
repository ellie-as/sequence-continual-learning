{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a231f9",
   "metadata": {},
   "source": [
    "### Generative vs. experience replay\n",
    "\n",
    "Comparing the effect of generative vs. experience replay on generalisation.\n",
    "\n",
    "#### Installation:\n",
    "\n",
    "Local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip tensorflow-macos==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f726ba-f622-4c8b-b0af-9330f10a4277",
   "metadata": {},
   "source": [
    "Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba8f20-ee5d-44c4-8d59-358fb79192c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wonderwords evaluate datasets accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12409883",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from continual_learning_utils import *\n",
    "from grid_environment_utils import * \n",
    "from testing_utils import * \n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "from scipy.stats import sem\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8424d28",
   "metadata": {},
   "source": [
    "#### Test generative replay\n",
    "\n",
    "Let's first create training data for 5 environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d2d1e-ab29-4f22-935e-fede85bef7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model_script(name_or_path='spatial_model', \n",
    "                       num_epochs=3,\n",
    "                       output_dir='./clm_script',\n",
    "                       save_steps=100,\n",
    "                       lr=5e-05):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    ! python ./run_clm.py \\\n",
    "        --model_name_or_path {name_or_path} \\\n",
    "        --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --validation_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'steps' \\\n",
    "        --save_steps {save_steps} \\\n",
    "        --learning_rate {lr} \n",
    "                           \n",
    "\n",
    "def train_on_env(training_strs, testing_strs, list_to_write, oversample_num=1000, eps=20, lr=5e-05, num_train=100, env=0, base_model='base_model', generated_strs=None):\n",
    "    !rm -rf spatial_model_{env}\n",
    "    !mkdir spatial_model_{env}\n",
    "\n",
    "    dirname = f'spatial_model_{env}'\n",
    "    \n",
    "    text_file = open(dirname + \"/train.txt\", \"w\")\n",
    "\n",
    "    list_to_write = np.random.choice(list_to_write, oversample_num).tolist()\n",
    "    n = text_file.write('\\n'.join(list_to_write))\n",
    "    text_file.close()\n",
    "\n",
    "    text_file = open(dirname + \"/test.txt\", \"w\")\n",
    "    n = text_file.write('\\n'.join(testing_strs[env]))\n",
    "    text_file.close()\n",
    "    \n",
    "    train_model_script(name_or_path=base_model, \n",
    "                       output_dir=dirname, \n",
    "                       num_epochs=eps, \n",
    "                       save_steps=2000,\n",
    "                       lr=lr)\n",
    "\n",
    "\n",
    "def get_mean_perplexity(input_texts, model_path='spatial_model_0'):\n",
    "    perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "    results = perplexity.compute(model_id=model_path,\n",
    "                                 add_start_token=False,\n",
    "                                 predictions=input_texts)\n",
    "    return results\n",
    "\n",
    "\n",
    "def generative_replay_v2(model, train_data, test_data, num=100, temperature=1, num_beams=5):\n",
    "    examples = []\n",
    "    all_data = train_data + test_data\n",
    "    shuffle(all_data)\n",
    "    for seq in test_data + train_data:\n",
    "        out = model.continue_input(seq[:seq.index('PATH:')+5], \n",
    "                                   do_sample=False, num_beams=5)\n",
    "        # Leave out the last sequence as it stopped midway through\n",
    "        out = out.split('\\n')[0]\n",
    "        if out in train_data or out in test_data:\n",
    "            examples.append(out)\n",
    "            print(f\"Appending {out} to training data\")\n",
    "    print(f\"{len(list(set(examples)))} unique examples in a list of {len(examples)}\")\n",
    "    return random.choices(list(set(examples)), k=num)\n",
    "\n",
    "\n",
    "def generative_replay_v3(model, train_data, test_data, num=100, temperature=1, num_beams=5):\n",
    "    examples = []\n",
    "    for seq in test_data + train_data:\n",
    "        out = model.continue_input(seq[:seq.index('PATH:')+5], \n",
    "                                   do_sample=False, num_beams=num_beams)\n",
    "        # Leave out the last sequence as it stopped midway through\n",
    "        out = out.split('\\n')[0]\n",
    "        #if out in train_data or out in test_data:\n",
    "        examples.append(out)\n",
    "        print(f\"Appending {out} to training data\")\n",
    "    examples = list(set(examples))\n",
    "    # ps = get_mean_perplexity(examples)['perplexities']\n",
    "    # ranked = [x for _, x in sorted(zip(ps, examples))][0:num]\n",
    "    return random.choices(examples, k=num) #ranked\n",
    "\n",
    "\n",
    "def experience_replay(i, training_strs, train_size=100, sample_size=10):\n",
    "    # Get sample_size items from the first train_size items of each previous environment\n",
    "    train_list = [training_strs[j][0:train_size] for j in range(0,i)]\n",
    "    # Flatten this list\n",
    "    train_list = [x for xs in train_list for x in xs]\n",
    "    return random.choices(train_list, k=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a921f-7d82-4344-b3c7-7c557799407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    \n",
    "    # Extract and organize data\n",
    "    exp_rep_next_loc = np.array([result['experience_replay'][0] for result in results.values()])\n",
    "    exp_rep_shortest_path = np.array([result['experience_replay'][1] for result in results.values()])\n",
    "    gen_rep_next_loc = np.array([result['generative_replay'][0] for result in results.values()])\n",
    "    gen_rep_shortest_path = np.array([result['generative_replay'][1] for result in results.values()])\n",
    "    \n",
    "    # Calculate means\n",
    "    means_exp_rep = [exp_rep_next_loc.mean(), exp_rep_shortest_path.mean()]\n",
    "    means_gen_rep = [gen_rep_next_loc.mean(), gen_rep_shortest_path.mean()]\n",
    "    \n",
    "    # Calculate SEMs\n",
    "    sems_exp_rep = [sem(exp_rep_next_loc), sem(exp_rep_shortest_path)]\n",
    "    sems_gen_rep = [sem(gen_rep_next_loc), sem(gen_rep_shortest_path)]\n",
    "    \n",
    "    # Plotting\n",
    "    x = np.arange(2)  # Number of groups\n",
    "    width = 0.35  # Width of bars\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    rects1 = ax.bar(x - width/2, means_exp_rep, width, yerr=sems_exp_rep, label='Experience replay', capsize=0, \n",
    "                    color='blue', alpha=0.5)\n",
    "    rects2 = ax.bar(x + width/2, means_gen_rep, width, yerr=sems_gen_rep, label='Generative replay', capsize=0, \n",
    "                    color='red', alpha=0.5)\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Next location prediction', 'Shortest path prediction'])\n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig('two_task_grouped_bar.png', dpi=500)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7128f-dd62-49cd-999f-31a18d189472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size=50\n",
    "sample_size=100\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(0, 5):\n",
    "    results[i] = {}\n",
    "    \n",
    "    training_strs, testing_strs = prepare_data(short_paths=True)\n",
    "    \n",
    "    list_to_write = training_strs[0][0:train_size]\n",
    "    train_on_env(training_strs, \n",
    "         testing_strs, \n",
    "         list_to_write,\n",
    "         eps=10, \n",
    "         lr=5e-05,\n",
    "         num_train=train_size, \n",
    "         env=0, \n",
    "         base_model='base_model_b8', \n",
    "         oversample_num=4000)\n",
    "    \n",
    "    # EXPERIENCE REPLAY\n",
    "    \n",
    "    replayed_strs = random.choices(training_strs[0][0:train_size], k=sample_size)\n",
    "    \n",
    "    print(f\"Replayed strings: {replayed_strs}\")\n",
    "    train_on_env(training_strs, \n",
    "                 testing_strs, \n",
    "                 training_strs[1][:train_size] + replayed_strs,\n",
    "                 eps=10, \n",
    "                 lr=5e-05,\n",
    "                 num_train=train_size, \n",
    "                 env=1, \n",
    "                 base_model=f'spatial_model_0',\n",
    "                 oversample_num=1000)\n",
    "    \n",
    "    # Test on all environments\n",
    "    model = GPT(base_model=f'spatial_model_1')\n",
    "    with open(f\"spatial_model_0/test.txt\", 'r') as file:\n",
    "        test_data = [line.strip() for line in file]\n",
    "    print(f\"Test data: {test_data}\")\n",
    "    accuracy = test_accuracy(model, test_data)\n",
    "    print(f\"Next node accuracy: {accuracy}\")    \n",
    "    \n",
    "    sp_accuracy = shortest_path_accuracy(model, \n",
    "                                      test_data_subset(test_data, training_strs[0][:train_size]), \n",
    "                                      training_strs[0] + testing_strs[0])\n",
    "    print(f\"Shortest path accuracy: {sp_accuracy}\")  \n",
    "    \n",
    "    results[i]['experience_replay'] = [accuracy, sp_accuracy]\n",
    "    \n",
    "    # GENERATIVE REPLAY\n",
    "    \n",
    "    generated_strs = generative_replay_v3(GPT(base_model=f'spatial_model_0'), \n",
    "                                          training_strs[0], \n",
    "                                          testing_strs[0], \n",
    "                                          num=sample_size,\n",
    "                                          num_beams=5)\n",
    "    \n",
    "    print(f\"Generated strings: {generated_strs}\")\n",
    "    train_on_env(training_strs, \n",
    "                 testing_strs, \n",
    "                 training_strs[1][:train_size] + generated_strs,\n",
    "                 eps=10, \n",
    "                 lr=5e-05,\n",
    "                 num_train=train_size, \n",
    "                 env=1, \n",
    "                 base_model=f'spatial_model_0',\n",
    "                 oversample_num=1000)\n",
    "\n",
    "    # Test on all environments\n",
    "    model = GPT(base_model=f'spatial_model_1')\n",
    "    with open(f\"spatial_model_0/test.txt\", 'r') as file:\n",
    "        test_data = [line.strip() for line in file]\n",
    "    print(f\"Test data: {test_data}\")\n",
    "    accuracy = test_accuracy(model, test_data)\n",
    "    print(f\"Next node accuracy: {accuracy}\")    \n",
    "    \n",
    "    sp_accuracy = shortest_path_accuracy(model, \n",
    "                                      test_data_subset(test_data, training_strs[0][:train_size]), \n",
    "                                      training_strs[0] + testing_strs[0])\n",
    "    print(f\"Shortest path accuracy: {sp_accuracy}\")  \n",
    "    \n",
    "    results[i]['generative_replay'] = [accuracy, sp_accuracy]\n",
    "    pd.DataFrame(results).to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c35ab-d2f2-481b-98da-d4bdb1686d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_exp_vs_gen_final.csv')\n",
    "\n",
    "desired_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    key = row['Unnamed: 0']\n",
    "    for col in df.columns[1:]:\n",
    "        value = eval(row[col])\n",
    "        if int(col) not in desired_dict:\n",
    "            desired_dict[int(col)] = {}\n",
    "        desired_dict[int(col)][key] = value\n",
    "\n",
    "plot_results(desired_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a6631-8db9-4ca2-a118-98b11a46ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    0: {'experience_replay': [1.0, 0.4], 'generative_replay': [1.0, 1.0]},\n",
    "    1: {'experience_replay': [1.0, 0.5], 'generative_replay': [1.0, 0.5]},\n",
    "    2: {'experience_replay': [1.0, 0.0], 'generative_replay': [1.0, 0.8]},\n",
    "    3: {'experience_replay': [0.85, 0.5], 'generative_replay': [0.85, 0.5]},\n",
    "    4: {'experience_replay': [0.7, 0.0], 'generative_replay': [0.85, 0.3]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938c7fd-d1ad-4256-b6dc-fc3709cfc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc30900-0951-4cbe-a714-b850c010a20e",
   "metadata": {},
   "source": [
    "#### Generative data augmentation\n",
    "\n",
    "Test effect of training on environmnent 0 with and without generative data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92036281-a212-4843-9504-fbe0bc8336a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size=50\n",
    "sample_size=100\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(0, 5):\n",
    "    results[i] = {}\n",
    "    \n",
    "    training_strs, testing_strs = prepare_data(short_paths=True)\n",
    "    \n",
    "    list_to_write = training_strs[0][0:train_size]\n",
    "    train_on_env(training_strs, \n",
    "         testing_strs, \n",
    "         list_to_write,\n",
    "         eps=10, \n",
    "         lr=5e-05,\n",
    "         num_train=train_size, \n",
    "         env=0, \n",
    "         base_model='base_model_b8', \n",
    "         oversample_num=4000)\n",
    "    \n",
    "    # EXPERIENCE REPLAY\n",
    "    \n",
    "    train_on_env(training_strs, \n",
    "                 testing_strs, \n",
    "                 training_strs[0][:train_size],\n",
    "                 eps=10, \n",
    "                 lr=5e-05,\n",
    "                 num_train=train_size, \n",
    "                 env=1, \n",
    "                 base_model=f'spatial_model_0',\n",
    "                 oversample_num=1000)\n",
    "    \n",
    "    # Test on all environments\n",
    "    model = GPT(base_model=f'spatial_model_1')\n",
    "    with open(f\"spatial_model_0/test.txt\", 'r') as file:\n",
    "        test_data = [line.strip() for line in file]\n",
    "    print(f\"Test data: {test_data}\")\n",
    "    accuracy = test_accuracy(model, test_data)\n",
    "    print(f\"Next node accuracy: {accuracy}\")    \n",
    "    \n",
    "    sp_accuracy = shortest_path_accuracy(model, \n",
    "                                      test_data_subset(test_data, training_strs[0][:train_size]), \n",
    "                                      training_strs[0] + testing_strs[0])\n",
    "    print(f\"Shortest path accuracy: {sp_accuracy}\")  \n",
    "    \n",
    "    results[i]['experience_replay'] = [accuracy, sp_accuracy]\n",
    "    \n",
    "    # GENERATIVE REPLAY\n",
    "    \n",
    "    generated_strs = generative_replay_v3(GPT(base_model=f'spatial_model_0'), \n",
    "                                          training_strs[0], \n",
    "                                          testing_strs[0], \n",
    "                                          num=sample_size,\n",
    "                                          num_beams=5)\n",
    "    \n",
    "    print(f\"Generated strings: {generated_strs}\")\n",
    "    train_on_env(training_strs, \n",
    "                 testing_strs, \n",
    "                 training_strs[0][:train_size] + generated_strs,\n",
    "                 eps=10, \n",
    "                 lr=5e-05,\n",
    "                 num_train=train_size, \n",
    "                 env=1, \n",
    "                 base_model=f'spatial_model_0',\n",
    "                 oversample_num=1000)\n",
    "\n",
    "    # Test on all environments\n",
    "    model = GPT(base_model=f'spatial_model_1')\n",
    "    with open(f\"spatial_model_0/test.txt\", 'r') as file:\n",
    "        test_data = [line.strip() for line in file]\n",
    "    print(f\"Test data: {test_data}\")\n",
    "    accuracy = test_accuracy(model, test_data)\n",
    "    print(f\"Next node accuracy: {accuracy}\")    \n",
    "    \n",
    "    sp_accuracy = shortest_path_accuracy(model, \n",
    "                                      test_data_subset(test_data, training_strs[0][:train_size]), \n",
    "                                      training_strs[0] + testing_strs[0])\n",
    "    print(f\"Shortest path accuracy: {sp_accuracy}\")  \n",
    "    \n",
    "    results[i]['generative_replay'] = [accuracy, sp_accuracy]\n",
    "    pd.DataFrame(results).to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daf31e-558f-42d5-8cdb-f1f56ff99e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
