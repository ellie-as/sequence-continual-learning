{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b0aaad-985d-44b4-915a-a78008d23858",
   "metadata": {},
   "source": [
    "### Analyse generated sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e151cc-05b3-4761-a24a-a5359ca6a11c",
   "metadata": {},
   "source": [
    "The data in the first two plots was generated with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faeb5a-a283-48e0-8ac0-7a745e9de874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generative_replay(model, num=100, temperature=1):\n",
    "#     examples = []\n",
    "#     while len(examples) < num:\n",
    "#         out = model.continue_input(\"FROM:\", \n",
    "#                                    do_sample=True,\n",
    "#                                    temperature=temperature)\n",
    "#         # Leave out the last sequence as it stopped midway through\n",
    "#         examples.extend(out.split('\\n')[:-1])\n",
    "#     shuffle(examples)\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# word_freq_results = []\n",
    "# train_size=50\n",
    "# sample_size=100\n",
    "\n",
    "# training_strs, testing_strs = prepare_data(default=True)\n",
    "\n",
    "# list_to_write = training_strs[0][0:train_size]\n",
    "# train_on_env(training_strs, \n",
    "#      testing_strs, \n",
    "#      list_to_write,\n",
    "#      eps=10, \n",
    "#      lr=5e-05,\n",
    "#      num_train=train_size, \n",
    "#      env=0, \n",
    "#      base_model='base_model_b8', \n",
    "#      oversample_num=4000)\n",
    "\n",
    "# temps = [0.3, 0.9, 1.5, 2.1]\n",
    "# for temp in temps:\n",
    "#     for i in range(5):\n",
    "    \n",
    "#         generated_strs = generative_replay(GPT(base_model=f'spatial_model_0'), \n",
    "#                                               temperature=temp)\n",
    "    \n",
    "#         locs = get_unique_locations(generated_strs)\n",
    "#         word_freq_results.append({'model': 1, \n",
    "#                                   'locs': locs, \n",
    "#                                   'temp': temp, \n",
    "#                                   'train_size': train_size, \n",
    "#                                   \"sample_size\": sample_size, \n",
    "#                                   \"seqs\": generated_strs, \n",
    "#                                   \"training_strs\": training_strs, \n",
    "#                                   \"testing_strs\": testing_strs})\n",
    "#         with open('word_freq_results_imagined.pkl', 'wb') as file:\n",
    "#             pickle.dump(word_freq_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c72df-5e7d-46d2-9c30-27b8100dc3a9",
   "metadata": {},
   "source": [
    "#### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819ce0c-3092-42a8-b8fb-a984f8ec82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from testing_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "\n",
    "input_file = 'word_freq_results_imagined_v2.pkl'\n",
    "\n",
    "# Loading the data from the pickle file\n",
    "with open(input_file, 'rb') as file:\n",
    "    results_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b80210-3dad-497f-9cac-dbd1d25100c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def analyze_sequences(results):\n",
    "    # Extract necessary data\n",
    "    current_env = results['model']  \n",
    "    training_strs = results['training_strs']\n",
    "    testing_strs = results['testing_strs']\n",
    "    train_size = results['train_size']\n",
    "    seqs = results['seqs']\n",
    "\n",
    "    # Initialize results storage\n",
    "    analysis_results = {'real': [], 'valid': [], 'neither': []}\n",
    "\n",
    "    # Iterate through each sequence in seqs\n",
    "    for seq in seqs:\n",
    "        found_as_real = False\n",
    "        found_as_valid = False\n",
    "\n",
    "        # Check for real sequences in previous phases\n",
    "        for i in range(current_env):\n",
    "            if seq in training_strs[i][0:train_size]:\n",
    "                analysis_results['real'].append(seq)\n",
    "                found_as_real = True\n",
    "                break  # Stop searching if found\n",
    "\n",
    "        if not found_as_real:\n",
    "            # Check for valid sequences if not found as real\n",
    "            for i in range(current_env):\n",
    "                if seq in training_strs[i][train_size:] or seq in testing_strs[i]:\n",
    "                    analysis_results['valid'].append(seq)\n",
    "                    found_as_valid = True\n",
    "                    break  # Stop searching if found\n",
    "\n",
    "        if not (found_as_real or found_as_valid):\n",
    "            # If the sequence is neither real nor valid\n",
    "            analysis_results['neither'].append(seq)\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd8751-445e-47ea-893c-06fc6a1ffb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sequences_by_temperature(results_dicts):\n",
    "    temperature_results = {}\n",
    "\n",
    "    for results in results_dicts:\n",
    "        temp = results['temp']  # Assuming 'temp' is how temperature is recorded\n",
    "        if temp == -1:  # Skip the analysis for temperature -1\n",
    "            continue\n",
    "        analysis_results = analyze_sequences(results)\n",
    "        total_length = len(analysis_results['real'] + analysis_results['valid'] + analysis_results['neither'])\n",
    "\n",
    "        # Initialize lists if this is the first time we're adding data for this temp\n",
    "        if temp not in temperature_results:\n",
    "            temperature_results[temp] = {'real': [], 'valid': [], 'neither': []}\n",
    "\n",
    "        if total_length > 0:\n",
    "            # Append the fraction to the list for each category\n",
    "            temperature_results[temp]['real'].append(len(analysis_results['real']) / total_length)\n",
    "            temperature_results[temp]['valid'].append(len(analysis_results['valid']) / total_length)\n",
    "            temperature_results[temp]['neither'].append(len(analysis_results['neither']) / total_length)\n",
    "        else:\n",
    "            # Optionally handle the case where total_length is 0; decide how you want to treat this case\n",
    "            pass  # For now, do nothing (or you could append 0 or None as placeholders)\n",
    "\n",
    "    return temperature_results\n",
    "\n",
    "def visualize_results(temperature_results):\n",
    "    temps = sorted(temperature_results.keys())\n",
    "    # Calculate means and SEMs\n",
    "    reals_means = [np.mean(temperature_results[temp]['real']) for temp in temps]\n",
    "    valids_means = [np.mean(temperature_results[temp]['valid']) for temp in temps]\n",
    "    neithers_means = [np.mean(temperature_results[temp]['neither']) for temp in temps]\n",
    "    \n",
    "    reals_sems = [sem(temperature_results[temp]['real']) for temp in temps]\n",
    "    valids_sems = [sem(temperature_results[temp]['valid']) for temp in temps]\n",
    "    neithers_sems = [sem(temperature_results[temp]['neither']) for temp in temps]\n",
    "\n",
    "    plt.figure(figsize=(3, 3)) \n",
    "    plt.errorbar(temps, reals_means, yerr=reals_sems, label='Real', marker='o', linestyle='-', capsize=5)\n",
    "    plt.errorbar(temps, valids_means, yerr=valids_sems, label='Valid', marker='s', linestyle='-', capsize=5)\n",
    "    plt.errorbar(temps, neithers_means, yerr=neithers_sems, label='Neither', marker='^', linestyle='-', capsize=5)\n",
    "\n",
    "    plt.xlabel('Temperature')\n",
    "    plt.ylabel('Fraction')\n",
    "    plt.legend()\n",
    "    plt.savefig('average_type_breakdown_by_temp_with_sem.png', dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "temperature_results = analyze_sequences_by_temperature(results_dict)\n",
    "visualize_results(temperature_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa842f4-0875-4ac5-a473-2dcca46a6642",
   "metadata": {},
   "source": [
    "#### Explore distribution of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88d210-4851-44eb-86b6-6959a67f7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_env = 1\n",
    "temps = [0.3, 0.9, 1.5, 2.1]\n",
    "# Initialize word_counts with lists for each env\n",
    "word_counts = {(model, temp): {env: [] for env in range(num_env)} for model in range(3) for temp in temps}\n",
    "\n",
    "for record in results_dict:\n",
    "    model, temp, locs, training_strs = record['model'], record['temp'], record['locs'], record['training_strs']\n",
    "    # Initialize 'No env' counts for each (model, temp) combination as a list\n",
    "    if 'No env' not in word_counts[(model, temp)]:\n",
    "        word_counts[(model, temp)]['No env'] = []\n",
    "    \n",
    "    # Initialize a counter for the current record's word counts\n",
    "    current_counts = {env: 0 for env in range(num_env)}\n",
    "    current_counts['No env'] = 0  # Also for 'No env'\n",
    "\n",
    "    for word in locs:\n",
    "        found = False\n",
    "        for env in range(num_env):\n",
    "            if word in get_unique_locations(training_strs[env]):\n",
    "                current_counts[env] += 1\n",
    "                found = True\n",
    "                break  # Assuming a word can only belong to one env, break if found\n",
    "        if not found:\n",
    "            current_counts['No env'] += 1\n",
    "    \n",
    "    # Append the counts from the current record to the corresponding lists in word_counts\n",
    "    for env in current_counts:\n",
    "        word_counts[(model, temp)][env].append(current_counts[env])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077cf6a-ad01-4913-a775-2dce9c31c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = [(1, 0.3), (1, 0.9), (1, 1.5), (1, 2.1)]\n",
    "\n",
    "temperatures = []\n",
    "total_real_locs = []\n",
    "total_fake_locs = []\n",
    "error_real_locs = []  # For SEM of real locations\n",
    "error_fake_locs = []  # For SEM of fake locations\n",
    "\n",
    "for d in data_to_plot:\n",
    "    temperatures.append(d[1])  # Extract temperature\n",
    "    real_locs = word_counts[d][0]  # List of counts for real locations\n",
    "    fake_locs = word_counts[d]['No env']  # List of counts for fake locations\n",
    "    \n",
    "    total_real_locs.append(np.mean(real_locs))\n",
    "    total_fake_locs.append(np.mean(fake_locs))\n",
    "    \n",
    "    error_real_locs.append(sem(real_locs))  # Calculate SEM for real locations\n",
    "    error_fake_locs.append(sem(fake_locs))  # Calculate SEM for fake locations\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.errorbar(temperatures, total_real_locs, yerr=error_real_locs, label='Real', marker='o', color='red', linestyle='-', capsize=5)\n",
    "plt.errorbar(temperatures, total_fake_locs, yerr=error_fake_locs, label='Imagined', marker='s', color='blue', linestyle='-', capsize=5)\n",
    "\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('No. unique locations')\n",
    "plt.legend()\n",
    "plt.savefig('loc_type_breakdown_by_temp.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d28d1c-f984-4375-ad7c-39d8b4098286",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'word_freq_results_imagined_final.pkl'\n",
    "\n",
    "# Loading the data from the pickle file\n",
    "with open(input_file, 'rb') as file:\n",
    "    results_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b32af-feb6-4ab9-a3ab-7a4c798a3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_env=5\n",
    "temps = [-1.0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]\n",
    "word_counts = {(model, temp): {env: 0 for env in range(num_env)} for model in range(5) for temp in temps}\n",
    "\n",
    "for record in results_dict:\n",
    "    model, temp, locs, training_strs = record['model'], record['temp'], record['locs'], record['training_strs']\n",
    "    if 'No env' not in word_counts[(model, temp)]:\n",
    "        word_counts[(model, temp)]['No env'] = 0\n",
    "    for word in locs:\n",
    "        found = False\n",
    "        for env in range(num_env):\n",
    "            if word in get_unique_locations(training_strs[env]):\n",
    "                word_counts[(model, temp)][env] += 1\n",
    "                found = True\n",
    "        if found is False:\n",
    "            word_counts[(model, temp)]['No env'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee87478-cb8a-42e8-8320-160f2e0aa76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(6, 7.5), sharex=True)\n",
    "bar_width = 0.20  \n",
    "\n",
    "for i, temp in enumerate([-1, 0.6, 1.2, 1.8]):\n",
    "    indices = np.arange(num_env)  \n",
    "    offsets = np.linspace(-bar_width * 5 / 2, bar_width * 5 / 2, 6)\n",
    "    \n",
    "    for j, env in enumerate(['No env'] + [env for env in range(num_env) if env != 4]):\n",
    "        env_data = [word_counts[(model, temp)].get(env, 0) for model in range(num_env)]\n",
    "        axes[i].bar(indices + offsets[j], env_data, width=bar_width, label=f'Env. {env}' if env != 'No env' else 'No env.')\n",
    "    \n",
    "    axes[i].set_xticks([i-(bar_width/2) for i in indices])  \n",
    "    axes[i].set_xticklabels([f'Env. {model}' for model in range(5)])\n",
    "    axes[i].set_xlabel('Training stage')\n",
    "    axes[i].set_ylabel('No. unique locations')\n",
    "    axes[i].set_title(f'{string.ascii_lowercase[i]}) Temperature of {temp}' if i > 0 else 'a) Experience replay')\n",
    "    axes[i].set_ylim(0,17)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('location_breakdown_by_temp.png', dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
