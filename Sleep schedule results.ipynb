{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a231f9",
   "metadata": {},
   "source": [
    "### Sleep simulations\n",
    "\n",
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip tensorflow-macos==2.11.0\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12409883",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleep_utils import *\n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b41698-4c4e-4631-a28b-18507f8e25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "\n",
    "    def continue_input(self, input_sequence, max_length=200, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab239d-3277-4efe-9ef6-e05841ff55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_script(name_or_path='spatial_model', \n",
    "                       num_epochs=3,\n",
    "                       output_dir='./clm_script',\n",
    "                       save_steps=100,\n",
    "                       lr=5e-05 ):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    ! python ./run_clm.py \\\n",
    "        --model_name_or_path {name_or_path} \\\n",
    "        --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --validation_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'steps' \\\n",
    "        --save_steps {save_steps} \\\n",
    "        --learning_rate {lr}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ab919-c400-4493-a3c7-8886d564b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomWord()\n",
    "\n",
    "def create_unique_random_grid(nouns, size=3):\n",
    "    \"\"\"Creates a size x size grid with unique random nouns.\"\"\"\n",
    "    random_nouns = random.sample(nouns, size * size)\n",
    "    return [random_nouns[i * size:(i + 1) * size] for i in range(size)]\n",
    "\n",
    "def find_shortest_paths(grid, start_name, end_name):\n",
    "    \"\"\"Finds all shortest paths from start_name to end_name in a grid. \"\"\"\n",
    "    # Find coordinates of start and end points\n",
    "    start = end = None\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, name in enumerate(row):\n",
    "            if name == start_name:\n",
    "                start = (i, j)\n",
    "            if name == end_name:\n",
    "                end = (i, j)\n",
    "    \n",
    "    # Check if start or end points were not found\n",
    "    if start is None or end is None:\n",
    "        print (\"start or end not found\")\n",
    "        return []\n",
    "\n",
    "    paths = []\n",
    "    start_x, start_y = start\n",
    "    end_x, end_y = end\n",
    "\n",
    "    # Total horizontal and vertical distances\n",
    "    x_dist = end_x - start_x\n",
    "    y_dist = end_y - start_y\n",
    "\n",
    "    # Generate a list of directions taken in the shortest path\n",
    "    # We know that the shortest route is x_dist EAST or WESTs, and y_dist NORTH or SOUTHs\n",
    "    hor_moves = ['EAST' if x_dist > 0 else 'WEST'] * abs(x_dist)\n",
    "    ver_moves = ['SOUTH' if y_dist > 0 else 'NORTH'] * abs(y_dist)\n",
    "    all_moves = hor_moves + ver_moves\n",
    "\n",
    "    # We have a list, e.g. [NORTH, NORTH, EAST, EAST] and we want to find all possible orderings\n",
    "    # Each ordering (i.e. permutation) is a possible shortest path from start_name to end_name\n",
    "    for path in set(permutations(all_moves, len(all_moves))):\n",
    "        sequence = [f'FROM: {start_name}, TO: {end_name}, PATH: {start_name}']\n",
    "        x, y = start\n",
    "        for direction in path:\n",
    "            if direction == 'EAST' and x < 2:\n",
    "                x += 1\n",
    "            elif direction == 'WEST' and x > 0:\n",
    "                x -= 1\n",
    "            elif direction == 'SOUTH' and y < 2:\n",
    "                y += 1\n",
    "            elif direction == 'NORTH' and y > 0:\n",
    "                y -= 1\n",
    "            else:\n",
    "                # Invalid move, skip this path\n",
    "                break\n",
    "            sequence.append(f\"{direction} {grid[x][y]}\")\n",
    "\n",
    "            # add the path when it successfully reaches the end point\n",
    "            if (x, y) == end:\n",
    "                paths.append(' '.join(sequence))\n",
    "\n",
    "    return paths\n",
    "  \n",
    "# # example usage\n",
    "# grid = create_unique_random_grid(nouns)\n",
    "# paths = find_shortest_paths(grid, grid[0][0], grid[2][2])\n",
    "\n",
    "# # print the grid and the paths to see the output\n",
    "# print(\"Grid:\", grid)\n",
    "# print(\"Shortest Paths:\", paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3e660-1cd8-4739-9654-63b9abb96965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_stimuli(stimuli):\n",
    "    random.shuffle(stimuli)\n",
    "    return stimuli\n",
    "\n",
    "def get_all_paths_for_grid(grid):\n",
    "    all_paths = []\n",
    "    items = [item for sublist in grid for item in sublist]\n",
    "    for start in items:\n",
    "        for end in items:\n",
    "            if start != end:\n",
    "                all_paths.extend(find_shortest_paths(grid, start, end))\n",
    "    return shuffle_stimuli(all_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8424d28",
   "metadata": {},
   "source": [
    "#### Test generative replay\n",
    "\n",
    "Let's first create training data for 5 environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d2d1e-ab29-4f22-935e-fede85bef7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_on_env(training_strs, testing_strs, env=0, base_model='base_model', generated_strs=[], num_train=1000, eps=20):\n",
    "    # if base_model != f'spatial_model_{env}':\n",
    "    #     !rm -rf spatial_model_{env}\n",
    "    #     !mkdir spatial_model_{env}\n",
    "    \n",
    "    text_file = open(f\"spatial_model_{env}/train.txt\", \"w\")\n",
    "    list_to_write = np.random.choice(training_strs[env], num_train).tolist()\n",
    "    \n",
    "    list_to_write.extend(generated_strs)\n",
    "    shuffle(list_to_write)\n",
    "    \n",
    "    n = text_file.write('\\n'.join(list_to_write))\n",
    "    text_file.close()\n",
    "\n",
    "    text_file = open(f\"spatial_model_{env}/test.txt\", \"w\")\n",
    "    n = text_file.write('\\n'.join(testing_strs[env]))\n",
    "    text_file.close()\n",
    "\n",
    "    print(f\"About to train model from {base_model} and save to spatial_model_{env}\")\n",
    "    \n",
    "    train_model_script(name_or_path=base_model, \n",
    "                       output_dir=f'spatial_model_{env}', \n",
    "                       num_epochs=eps, \n",
    "                       save_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698e1f8-8c87-4c13-9d74-8d0f869ed4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_replay(model, num=100, temperature=1):\n",
    "    examples = []\n",
    "    while len(examples) < num:\n",
    "        out = model.continue_input(\"FROM:\", \n",
    "                                   do_sample=True,\n",
    "                                   temperature=temperature)\n",
    "        examples.extend(out.split('\\n'))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38089487-731c-463c-969b-ec624d37060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    directions = ['NORTH', 'EAST', 'SOUTH', 'WEST']\n",
    "\n",
    "    for sequence in test_data:\n",
    "        # Find the first direction in the PATH and create the input sequence up to that point\n",
    "        first_direction_index = next((i for i, word in enumerate(sequence.split()) if word in directions), None)\n",
    "        if first_direction_index is not None:\n",
    "            # Prepare the input sequence up to and including the first direction\n",
    "            input_sequence = ' '.join(sequence.split()[:first_direction_index + 1])\n",
    "            \n",
    "            # Generate the model's prediction\n",
    "            full_predicted_sequence = model.continue_input(input_sequence)\n",
    "            # Remove the input part from the predicted sequence\n",
    "            predicted_sequence = full_predicted_sequence[len(input_sequence):].strip()\n",
    "            predicted_token = predicted_sequence.split()[0]  # First word of the generation\n",
    "\n",
    "            # Extract the corresponding true token\n",
    "            target_token = sequence.split()[first_direction_index + 1]\n",
    "\n",
    "            # Compare the predicted token with the true token\n",
    "            total_predictions += 1\n",
    "            print(f\"Correct location: {target_token}, Predicted location: {predicted_token}\")\n",
    "            if predicted_token == target_token:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "def get_mean_perplexity(input_texts, model_path):\n",
    "    perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "    results = perplexity.compute(model_id=model_path,\n",
    "                                 add_start_token=False,\n",
    "                                 predictions=input_texts)\n",
    "    return results['mean_perplexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad7f23-511e-482e-a444-aec75fbae727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    training_strs = []\n",
    "    testing_strs = []\n",
    "    for i in range(5):\n",
    "        nouns = [r.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\") for _ in range(9)]\n",
    "        grid = create_unique_random_grid(nouns)\n",
    "        print(grid)\n",
    "        pths = get_all_paths_for_grid(grid)\n",
    "        training_strs.append(pths[0:100])\n",
    "        testing_strs.append(pths[100:])\n",
    "    \n",
    "    for env in range(5):\n",
    "        if os.path.exists(f\"spatial_model_{env}\") is False:\n",
    "            os.mkdir(f\"spatial_model_{env}\")\n",
    "        text_file = open(f\"spatial_model_{env}/test.txt\", \"w\")\n",
    "        n = text_file.write('\\n'.join(testing_strs[env]))\n",
    "        text_file.close()\n",
    "    \n",
    "    return training_strs, testing_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8a236-9cbe-4c3e-9988-bbce9b2cd191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_paired_bar(results):\n",
    "    # Convert results to a structured array\n",
    "    structured_data = np.concatenate([np.array(res[0]) for res in results])\n",
    "\n",
    "    # Determine unique test environments\n",
    "    test_envs = np.unique(structured_data[:, 1])\n",
    "\n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    bar_width = 0.35\n",
    "    opacity = 0.8\n",
    "\n",
    "    # Process data for each test environment\n",
    "    for i, env in enumerate(test_envs):\n",
    "        # Filter data for each environment and phase\n",
    "        before_data = structured_data[(structured_data[:, 1] == env) & (structured_data[:, 0] == 0)]\n",
    "        after_data = structured_data[(structured_data[:, 1] == env) & (structured_data[:, 0] == 1)]\n",
    "\n",
    "        # Calculate mean and SEM for before and after\n",
    "        means = [np.mean(before_data[:, 2]), np.mean(after_data[:, 2])]\n",
    "        errors = [sem(before_data[:, 2]), sem(after_data[:, 2])]\n",
    "\n",
    "        # Create bars for this test environment\n",
    "        ax.bar(np.arange(len(means)) + i * bar_width, means, bar_width, alpha=opacity, color=plt.cm.Paired(i), yerr=errors, label=f'Test Env {int(env)}')\n",
    "\n",
    "    ax.set_xlabel('Training Phase')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy before and after \\'sleep\\'')\n",
    "    ax.set_xticks(np.arange(len(means)) + bar_width / 2)\n",
    "    ax.set_xticklabels(['Before', 'After'])\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def perplexity_plot(results):\n",
    "    # Combine all perplexity results\n",
    "    combined_perplexity = np.concatenate([np.array(res[1]) for res in results])\n",
    "\n",
    "    # Plot perplexity\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    colors = ['blue', 'green']  # Assuming 2 testing environments, assign a color to each\n",
    "\n",
    "    for j in range(2):  # Assuming 2 testing environments\n",
    "        env_perplexity = combined_perplexity[combined_perplexity[:, 1] == j]\n",
    "        cycles = np.unique(env_perplexity[:, 0])\n",
    "\n",
    "        mean_perplexities = [np.mean(env_perplexity[env_perplexity[:, 0] == cycle, 2]) for cycle in cycles]\n",
    "        perplexity_sems = [sem(env_perplexity[env_perplexity[:, 0] == cycle, 2]) for cycle in cycles]\n",
    "\n",
    "        ax.errorbar(cycles, mean_perplexities, yerr=perplexity_sems, label=f'Test: Env {j}', marker='o', color=colors[j])\n",
    "\n",
    "    ax.set_xlabel('Cycle')\n",
    "    ax.set_ylabel('Perplexity')\n",
    "    ax.set_title('Model Perplexity Across Cycles')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f06049-0f01-4480-9b36-11aebef7db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from generative_model import VAE\n",
    "from generative_tests import check_generative_recall\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.backends.backend_pdf\n",
    "from generative_model import models_dict\n",
    "import matplotlib\n",
    "import random\n",
    "\n",
    "training_strs, testing_strs = prepare_data()\n",
    "\n",
    "\n",
    "def train_with_schedule(total_eps=100, num_cycles=20, start_fraction_rem=0.2, end_fraction_rem=0.8,\n",
    "                        seed=0, lr=0.001, num=100, temperature=1):\n",
    "\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    eps_per_cycle = int(total_eps / num_cycles)\n",
    "\n",
    "    # Train on env. 0\n",
    "    train_on_env(training_strs, testing_strs, env=0, base_model='base_model', generated_strs=[])\n",
    "    \n",
    "    perplexity_results = []\n",
    "    for cycle in range(num_cycles):\n",
    "        \n",
    "        current_fraction_rem = start_fraction_rem + (end_fraction_rem - start_fraction_rem) * cycle / (num_cycles - 1)\n",
    "        # Update the nrem_eps and rem_eps values for this cycle\n",
    "        rem_eps = int(current_fraction_rem * eps_per_cycle)\n",
    "        nrem_eps = eps_per_cycle - rem_eps\n",
    "        \n",
    "        # train for nrem_eps on real fmnist\n",
    "        print(\"NREM phase\")\n",
    "        train_on_env(training_strs, \n",
    "                     testing_strs, \n",
    "                     env=1, \n",
    "                     base_model='spatial_model_0' if cycle == 0 else f'spatial_model_1',\n",
    "                     generated_strs=[], \n",
    "                     num_train=num,\n",
    "                     eps=nrem_eps)\n",
    "        \n",
    "        # train for rem_eps on sampled mnist\n",
    "        print(\"REM phase\")\n",
    "        generated_strs = generative_replay(GPT(base_model='spatial_model_1'), num=num, temperature=temperature)\n",
    "        print(generated_strs[0:5])\n",
    "        train_on_env(training_strs, \n",
    "                     testing_strs, \n",
    "                     env=1, \n",
    "                     base_model=f'spatial_model_1',\n",
    "                     generated_strs=generated_strs, \n",
    "                     num_train=0,\n",
    "                     eps=rem_eps)\n",
    "    \n",
    "        for j in range(2):\n",
    "            with open(f\"spatial_model_{j}/test.txt\", 'r') as file:\n",
    "                test_data = [line.strip() for line in file]\n",
    "            perplexity = get_mean_perplexity(test_data, 'spatial_model_1')\n",
    "            perplexity_results.append([cycle, j, perplexity])\n",
    "        print(\"Perplexity results so far:\")\n",
    "        print(perplexity_results)\n",
    "\n",
    "    # Test on all environments\n",
    "    results = []\n",
    "    for i in range(2):\n",
    "        model = GPT(base_model=f'spatial_model_{i}')\n",
    "        for j in range(2):\n",
    "            with open(f\"spatial_model_{j}/test.txt\", 'r') as file:\n",
    "                test_data = [line.strip() for line in file]\n",
    "            accuracy = test_accuracy(model, test_data)\n",
    "            results.append([i, j, accuracy])\n",
    "\n",
    "    return results, perplexity_results\n",
    "\n",
    "\n",
    "def train_with_schedule_multiple_seeds(seeds=[0], total_eps=100, num_cycles=20, start_fraction_rem=0.2, end_fraction_rem=0.8,\n",
    "                                       lr=0.001, num=10):\n",
    "    \n",
    "    pdf_path = \"./outputs/total_eps={}_num_cycles={}_start_rem={}_end_rem={}_lr={}_num={}.pdf\".format(str(total_eps),\n",
    "                                                                                                                  str(num_cycles),\n",
    "                                                                                                                  str(start_fraction_rem),\n",
    "                                                                                                                  str(end_fraction_rem),\n",
    "                                                                                                                  str(lr),\n",
    "                                                                                                                  str(num))\n",
    "\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(pdf_path)\n",
    "    \n",
    "    eps_per_cycle = int(total_eps / num_cycles)\n",
    "    fig = plot_schedule(num_cycles, total_eps, eps_per_cycle, start_fraction_rem, end_fraction_rem)\n",
    "    pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "    \n",
    "    results = [train_with_schedule(total_eps=total_eps,\n",
    "                                   num_cycles=num_cycles,\n",
    "                                   start_fraction_rem=start_fraction_rem,\n",
    "                                   end_fraction_rem=end_fraction_rem,\n",
    "                                   lr=lr,\n",
    "                                   seed=s,\n",
    "                                   num=num) for s in seeds]\n",
    "\n",
    "    fig = accuracy_paired_bar(results)\n",
    "    pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "    fig = perplexity_plot(results)\n",
    "    pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "    pdf.close()\n",
    "    return results\n",
    "   \n",
    "\n",
    "def plot_schedule(NUM_CYCLES, TOTAL_EPS, eps_per_cycle, starting_fraction_rem, ending_fraction_rem):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 2)\n",
    "\n",
    "    nrem_starts = list(range(0, TOTAL_EPS, int(eps_per_cycle)))\n",
    "    \n",
    "    for cycle in range(NUM_CYCLES):\n",
    "        # Calculate the current fraction of REM sleep for this cycle\n",
    "        current_fraction_rem = starting_fraction_rem + (ending_fraction_rem - starting_fraction_rem) * cycle / (NUM_CYCLES - 1)\n",
    "\n",
    "        # Update the nrem_eps and rem_eps values for this cycle\n",
    "        rem_eps = int(current_fraction_rem * eps_per_cycle)\n",
    "        nrem_eps = eps_per_cycle - rem_eps\n",
    "\n",
    "        rem_start = nrem_starts[cycle] + nrem_eps\n",
    "        \n",
    "        ax.broken_barh([(rem_start, rem_eps)],\n",
    "                       (10, 9),\n",
    "                       facecolors='tab:blue')\n",
    "        ax.broken_barh([(nrem_starts[cycle], nrem_eps)],\n",
    "                       (20, 9),\n",
    "                       facecolors='tab:red')\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_yticks([15, 25], labels=['REM', 'NREM'])\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d1894-b476-4e4f-9cc2-ed69157a474b",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b198f3-4551-44ef-a911-27173f877dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_with_schedule_multiple_seeds(seeds=[0], \n",
    "                                   total_eps=100, \n",
    "                                   num_cycles=25, \n",
    "                                   start_fraction_rem=0.5, \n",
    "                                   end_fraction_rem=0.5,\n",
    "                                   lr=0.001,\n",
    "                                   num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd1fa-ee9f-4c41-a0b2-d3170e7bff0e",
   "metadata": {},
   "source": [
    "#### Number of cycles comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b87f6d-7722-4e26-bedf-37deef5f7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_schedule_multiple_seeds(seeds=[0,1,2], \n",
    "                                   total_eps=100, \n",
    "                                   num_cycles=10, \n",
    "                                   start_fraction_rem=0.5, \n",
    "                                   end_fraction_rem=0.5,\n",
    "                                   lr=0.001,\n",
    "                                   num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d782065-6433-4f60-af56-5f879c766dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_schedule_multiple_seeds(seeds=[0,1,2], \n",
    "                                   total_eps=100, \n",
    "                                   num_cycles=5, \n",
    "                                   start_fraction_rem=0.5, \n",
    "                                   end_fraction_rem=0.5,\n",
    "                                   lr=0.001,\n",
    "                                   num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9b0b0-9116-4774-ad5d-30f1f6617be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_with_schedule_multiple_seeds(seeds=[0,1], \n",
    "                                   total_eps=100, \n",
    "                                   num_cycles=10, \n",
    "                                   start_fraction_rem=0.8, \n",
    "                                   end_fraction_rem=0.8,\n",
    "                                   lr=0.001,\n",
    "                                   num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba124bb-71a0-4b2a-a9f7-738966d72d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_schedule_multiple_seeds(seeds=[0], \n",
    "                                   total_eps=100, \n",
    "                                   num_cycles=5, \n",
    "                                   start_fraction_rem=1.0, \n",
    "                                   end_fraction_rem=1.0,\n",
    "                                   lr=0.001,\n",
    "                                   num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fbb5d-c297-4603-8b86-7afffb7073a1",
   "metadata": {},
   "source": [
    "#### NREM/REM ratio comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61c63f-d96d-41c3-869a-916569b2d215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89d07a81-ddc7-4aa6-bed6-b9db6147254a",
   "metadata": {},
   "source": [
    "#### Temperature comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d75931-d2ee-48e3-a704-e0b6e49bfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_with_schedule_multiple_seeds(seeds=[0], \n",
    "#                                    total_eps=100, \n",
    "#                                    num_cycles=10, \n",
    "#                                    start_fraction_rem=0.5, \n",
    "#                                    end_fraction_rem=0.5,\n",
    "#                                    lr=0.001,\n",
    "#                                    num=100,\n",
    "#                                    temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc43b0a-2755-459c-9d99-0145df2a31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_with_schedule_multiple_seeds(seeds=[0], \n",
    "#                                    total_eps=100, \n",
    "#                                    num_cycles=10, \n",
    "#                                    start_fraction_rem=0.5, \n",
    "#                                    end_fraction_rem=0.5,\n",
    "#                                    lr=0.001,\n",
    "#                                    num=100,\n",
    "#                                    temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddef4dd-6528-4186-af79-1ba0ebdea095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_with_schedule_multiple_seeds(seeds=[0], \n",
    "#                                    total_eps=100, \n",
    "#                                    num_cycles=10, \n",
    "#                                    start_fraction_rem=0.5, \n",
    "#                                    end_fraction_rem=0.5,\n",
    "#                                    lr=0.001,\n",
    "#                                    num=100,\n",
    "#                                    temperature=1.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
